{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from torch.nn.utils import rnn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 1033\n"
     ]
    }
   ],
   "source": [
    "with open('../Dataset/Cora/cora.cites') as fs:\n",
    "    for line in fs:\n",
    "        temp = list(map(int,line.strip().split()))\n",
    "        print(temp[0],temp[1])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct network\n",
    "G = nx.Graph()\n",
    "count = 0\n",
    "node_list = {} # assign a id of 0 - n (n nodes...)\n",
    "with open('../Dataset/Cora/cora.cites') as fs:\n",
    "    for line in fs:\n",
    "        u,v = map(int,line.strip().split())\n",
    "        if u not in node_list:\n",
    "            node_list[u] = count\n",
    "            count+=1\n",
    "        if v not in node_list:\n",
    "            node_list[v] = count\n",
    "            count+=1\n",
    "        G.add_edge(node_list[u],node_list[v])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining node features...\n",
    "feature = [[] for i in range(len(node_list))]\n",
    "label = {}\n",
    "with open('../Dataset/Cora/cora.content') as fs:\n",
    "    for line in fs:\n",
    "        temp = line.strip().split()\n",
    "        node = node_list[int(temp[0])]\n",
    "        label = temp[-1]\n",
    "        feature[node] = list(map(int,temp[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = torch.FloatTensor(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,feature,graph,input_size,hidden_size):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.feature = feature\n",
    "        self.graph = graph\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.W_1 = nn.Parameter(torch.rand(input_size,hidden_size))\n",
    "        self.W_2 = nn.Parameter(torch.rand(input_size,hidden_size))\n",
    "        \n",
    "        self.U_1 = nn.Parameter(torch.rand(hidden_size))\n",
    "        self.U_2 = nn.Parameter(torch.rand(hidden_size))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "        \n",
    "    def forward(self,node_sample):\n",
    "        \n",
    "        C_n_1_u = torch.matmul(feature,self.W_1)\n",
    "        \n",
    "        C_n_2_u = torch.matmul(feature,self.W_2)\n",
    "        \n",
    "        s_node_repr = torch.Tensor()\n",
    "        \n",
    "        for node in node_sample:\n",
    "            \n",
    "            nbr_1 = torch.Tensor()\n",
    "            nbr_2 = torch.Tensor()\n",
    "            # obtaining the first hop neighbors\n",
    "            neighbors_1 = list(nx.neighbors(G,node))\n",
    "            \n",
    "            # obtaining the second hop neighbors\n",
    "            neighbors_2 = []\n",
    "            for n in neighbors_1:\n",
    "                nbr_1 = torch.cat((nbr_1,C_n_1_u[n].view(1,-1)),dim=0) # getting the vectors of neighbors\n",
    "                neighbors_2 += list(nx.neighbors(G,n))\n",
    "            \n",
    "            neighbors_2 = list(set(neighbors_2))\n",
    "            \n",
    "            for n in neighbors_2:\n",
    "                nbr_2 = torch.cat((nbr_2,C_n_2_u[n].view(1,-1)),dim=0) # getting vectors of two-hop neighbors\n",
    "            \n",
    "            # calculate attention weights for 1-hop neighbors\n",
    "            \n",
    "            att_wt_1 = self.softmax(torch.sum(nbr_1*self.U_1,dim=1).view(-1,1))\n",
    "            att_wt_2 = self.softmax(torch.sum(nbr_2*self.U_2,dim=1).view(-1,1))\n",
    "            \n",
    "            output = torch.cat((torch.sum(nbr_1*att_wt_1,dim=0),torch.sum(nbr_2*att_wt_2,dim=0)),dim=0).view(1,-1)\n",
    "            \n",
    "            s_node_repr = torch.cat((s_node_repr,output),dim=0)\n",
    "            \n",
    "        return s_node_repr    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomWalk(G,node,walk_length = 3,walk_num=10): # finding list of similar nodes\n",
    "    sim_nodes = Counter()\n",
    "    for i in range(walk_num):\n",
    "        l = 0\n",
    "        c_node = node\n",
    "        while(l<walk_length):\n",
    "            n = random.select(list(nx.neighbors(G,c_node)),1)\n",
    "            sim_nodes[n]+=1\n",
    "            c_node = n\n",
    "            l+=1\n",
    "    return list(sim_nodes)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSimilarNodes(G):\n",
    "    similar_nodes = {}\n",
    "    for node in G.nodes():\n",
    "        similar_nodes[node] = randomWalk(G,node)\n",
    "    return similar_nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSamples(G,sample_nodes,all_edges): # generates positive and negative samples for a given batch of nodes\n",
    "    pos_sample_edges = list(filter(lambda x:x[0] in sample_nodes and x[1] in sample_nodes,all_edges))\n",
    "    neg_sample_size = len(pos_sample_edges)\n",
    "    neg_sample_edges = []\n",
    "    i=0\n",
    "    tries = 2*neg_sample_size # check to keep the number of tries finite\n",
    "    while i<neg_sample_size:\n",
    "        u,v = random.sample(sample_nodes,2)\n",
    "        if (u,v) not in pos_sample_edges and (v,u) not in pos_sample_edges:\n",
    "            neg_sample_edges.append((u,v))\n",
    "            i+=1\n",
    "        tries-=1\n",
    "        if tries==0:\n",
    "            break\n",
    "    return pos_sample_edges,neg_sample_edges        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBatches(Graph = G,batch_size = 1,node_list=[],edge_list=[]):\n",
    "    random.shuffle(node_list)\n",
    "    num_batches = int(len(node_list)/batch_size)+1\n",
    "    for i in range(num_batches):\n",
    "        # get nodes for batches...\n",
    "        if i<num_batches-1:\n",
    "            sample_nodes = node_list[i*batch_size:(i+1)*batch_size]\n",
    "        else:\n",
    "            sample_nodes = node_list[i*batch_size:]\n",
    "\n",
    "        # find positive and negative samples for a batch\n",
    "        pos_sample_edges, neg_sample_edges = getSamples(G,sample_nodes,edge_list)\n",
    "        \n",
    "        node_dict = {}\n",
    "        count = 0\n",
    "        \n",
    "        for n in sample_nodes:\n",
    "            node_dict[n] = count\n",
    "            count+=1\n",
    "        \n",
    "        yield pos_sample_edges,neg_sample_edges,sample_nodes,node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, graph=G, batch_size=25, epochs=1, learning_rate=0.001):\n",
    "    optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    node_list = list(G.nodes())\n",
    "    edge_list = list(G.edges())\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        \n",
    "        for pos_sample, neg_sample, sample_nodes,node_dict in \\\n",
    "        createBatches(Graph=G, batch_size=batch_size, node_list=node_list, edge_list=edge_list):\n",
    "            \n",
    "    \n",
    "            node_repr = encoder(sample_nodes)\n",
    "            \n",
    "            \n",
    "            predicted_vector = torch.Tensor()\n",
    "            true_label = torch.FloatTensor([1 for i in range(len(pos_sample))]+[0 for i in range\n",
    "                                                                                   (len(neg_sample))]).view(1,-1)\n",
    "            \n",
    "            \n",
    "            i = 0\n",
    "            for a,b in pos_sample+neg_sample:\n",
    "                u = node_dict[a]\n",
    "                v = node_dict[b]\n",
    "                pred_val = F.sigmoid(torch.sum(node_repr[u]*node_repr[v])).view(1,1)\n",
    "                \n",
    "                predicted_vector = torch.cat((predicted_vector, pred_val),dim=0)\n",
    "            \n",
    "            loss = criterion(predicted_vector,true_label)\n",
    "            \n",
    "            print('loss: {}'.format(loss))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRepresentations(encoder,G):\n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    node_repr = encoder(nodes)\n",
    "    \n",
    "    return node_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n",
      "loss: 0.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-2dcf09c54804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-178-6eb2e9bc71f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, graph, batch_size, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = feature.shape[1]\n",
    "hidden_size = 100\n",
    "encoder = Encoder(feature,G,input_size,hidden_size)\n",
    "batch_size = 100\n",
    "train(encoder,graph=G,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[1,2,3],[3,4,5]])\n",
    "y = torch.Tensor([3,4]).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  6.,  9.],\n",
      "        [12., 16., 20.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([15., 22., 29.])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x*y)\n",
    "torch.sum(x*y,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
