{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from torch.nn.utils import rnn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 1033\n"
     ]
    }
   ],
   "source": [
    "with open('../Dataset/Cora/cora.cites') as fs:\n",
    "    for line in fs:\n",
    "        temp = list(map(int,line.strip().split()))\n",
    "        print(temp[0],temp[1])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct network\n",
    "G = nx.Graph()\n",
    "count = 0\n",
    "node_list = {} # assign a id of 0 - n (n nodes...)\n",
    "with open('../Dataset/Cora/cora.cites') as fs:\n",
    "    for line in fs:\n",
    "        u,v = map(int,line.strip().split())\n",
    "        if u not in node_list:\n",
    "            node_list[u] = count\n",
    "            count+=1\n",
    "        if v not in node_list:\n",
    "            node_list[v] = count\n",
    "            count+=1\n",
    "        G.add_edge(node_list[u],node_list[v])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining node features...\n",
    "feature = [[] for i in range(len(node_list))]\n",
    "label = {}\n",
    "with open('../Dataset/Cora/cora.content') as fs:\n",
    "    for line in fs:\n",
    "        temp = line.strip().split()\n",
    "        node = node_list[int(temp[0])]\n",
    "        label = temp[-1]\n",
    "        feature[node] = list(map(int,temp[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = torch.FloatTensor(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,feature,graph,input_size,hidden_size):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.feature = feature\n",
    "        self.graph = graph\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.W_1 = nn.Parameter(torch.rand(input_size,hidden_size))\n",
    "        self.W_2 = nn.Parameter(torch.rand(input_size,hidden_size))\n",
    "        \n",
    "        self.U_1 = nn.Parameter(torch.rand(hidden_size))\n",
    "        self.U_2 = nn.Parameter(torch.rand(hidden_size))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "        \n",
    "    def forward(self,node_sample):\n",
    "        \n",
    "        C_n_1_u = torch.matmul(feature,self.W_1)\n",
    "        \n",
    "        C_n_2_u = torch.matmul(feature,self.W_2)\n",
    "        \n",
    "        s_node_repr = torch.Tensor()\n",
    "        \n",
    "        for node in node_sample:\n",
    "            \n",
    "            nbr_1 = torch.Tensor()\n",
    "            nbr_2 = torch.Tensor()\n",
    "            # obtaining the first hop neighbors\n",
    "            neighbors_1 = list(nx.neighbors(G,node))\n",
    "            \n",
    "            # obtaining the second hop neighbors\n",
    "            neighbors_2 = []\n",
    "            for n in neighbors_1:\n",
    "                nbr_1 = torch.cat((nbr_1,C_n_1_u[n].view(1,-1)),dim=0) # getting the vectors of neighbors\n",
    "                neighbors_2 += list(nx.neighbors(G,n))\n",
    "            \n",
    "            neighbors_2 = list(set(neighbors_2))\n",
    "            \n",
    "            for n in neighbors_2:\n",
    "                nbr_2 = torch.cat((nbr_2,C_n_2_u[n].view(1,-1)),dim=0) # getting vectors of two-hop neighbors\n",
    "            \n",
    "            # calculate attention weights for 1-hop neighbors\n",
    "            \n",
    "            att_wt_1 = self.softmax(torch.sum(nbr_1*self.U_1,dim=1).view(-1,1))\n",
    "            att_wt_2 = self.softmax(torch.sum(nbr_2*self.U_2,dim=1).view(-1,1))\n",
    "            \n",
    "            output = torch.cat((torch.sum(nbr_1*att_wt_1,dim=0),torch.sum(nbr_2*att_wt_2,dim=0)),dim=0).view(1,-1)\n",
    "            #print(output)\n",
    "            \n",
    "            s_node_repr = torch.cat((s_node_repr,output),dim=0)\n",
    "            \n",
    "        return s_node_repr    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomWalk(G,node,walk_length = 3,walk_num=10): # finding list of similar nodes\n",
    "    sim_nodes = Counter()\n",
    "    for i in range(walk_num):\n",
    "        l = 0\n",
    "        c_node = node\n",
    "        while(l<walk_length):\n",
    "            n = random.choice(list(nx.neighbors(G,c_node)),1)\n",
    "            sim_nodes[n]+=1\n",
    "            c_node = n\n",
    "            l+=1\n",
    "    return list(sim_nodes)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSimilarNodes(G):\n",
    "    similar_nodes = {}\n",
    "    for node in G.nodes():\n",
    "        similar_nodes[node] = randomWalk(G,node)\n",
    "    return similar_nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSamples(G,sample_nodes,all_edges): # generates positive and negative samples for a given batch of nodes\n",
    "    pos_sample_edges = list(filter(lambda x:x[0] in sample_nodes and x[1] in sample_nodes,all_edges))\n",
    "    neg_sample_size = len(pos_sample_edges)\n",
    "    neg_sample_edges = []\n",
    "    i=0\n",
    "    tries = 2*neg_sample_size # check to keep the number of tries finite\n",
    "    while i<neg_sample_size:\n",
    "        u,v = random.sample(sample_nodes,2)\n",
    "        if (u,v) not in pos_sample_edges and (v,u) not in pos_sample_edges:\n",
    "            neg_sample_edges.append((u,v))\n",
    "            i+=1\n",
    "        tries-=1\n",
    "        if tries==0:\n",
    "            break\n",
    "    return pos_sample_edges,neg_sample_edges        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBatches(Graph = G,batch_size = 1,node_list=[],edge_list=[]):\n",
    "    random.shuffle(node_list)\n",
    "    num_batches = int(len(node_list)/batch_size)+1\n",
    "    for i in range(num_batches):\n",
    "        # get nodes for batches...\n",
    "        if i<num_batches-1:\n",
    "            sample_nodes = node_list[i*batch_size:(i+1)*batch_size]\n",
    "        else:\n",
    "            sample_nodes = node_list[i*batch_size:]\n",
    "\n",
    "        # find positive and negative samples for a batch\n",
    "        pos_sample_edges, neg_sample_edges = getSamples(Graph,sample_nodes,edge_list)\n",
    "        \n",
    "        node_dict = {}\n",
    "        count = 0\n",
    "        \n",
    "        for n in sample_nodes:\n",
    "            node_dict[n] = count\n",
    "            count+=1\n",
    "        \n",
    "        yield pos_sample_edges,neg_sample_edges,sample_nodes,node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biasedRandomWalk(u,Graph,sample_size): # mix of BFS and DFS\n",
    "    node_c = 1\n",
    "    sample = [u]\n",
    "    curr_node = u\n",
    "    while node_c<sample_size:\n",
    "        \n",
    "        nbrs = list(nx.neighbors(Graph,curr_node))\n",
    "        \n",
    "        if random.uniform(0,1)<0.5:\n",
    "            v = random.choice(nbrs)\n",
    "            curr_node = v\n",
    "            sample.append(v)\n",
    "            node_c+=1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if len(nbrs)< sample_size - node_c:\n",
    "                sample+= nbrs\n",
    "                node_c+= len(nbrs)\n",
    "\n",
    "            else:\n",
    "                to_add = sample_size - node_c\n",
    "                sample += nbrs[:to_add]\n",
    "                node_c += len(nbrs[:to_add])\n",
    "                \n",
    "            curr_node = random.choice(nbrs)    \n",
    "     \n",
    "    return list(set(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBatchesSubgraph(Graph = '',batch_size = '',node_list='',edge_list=''):\n",
    "    \n",
    "    num_batches = 2*int(len(node_list)/batch_size)\n",
    "    \n",
    "    for _ in range(num_batches):\n",
    "    \n",
    "        batch_size_pos = int(0.8*batch_size)\n",
    "        batch_size_neg = batch_size - batch_size_pos\n",
    "        u = random.choice(node_list)\n",
    "        sample_nodes = biasedRandomWalk(u,Graph,batch_size_pos)\n",
    "        sample_nodes += random.sample(node_list, batch_size-len(sample_nodes))\n",
    "\n",
    "        sample_nodes = list(set(sample_nodes))\n",
    "        \n",
    "        pos_sample_edges, neg_sample_edges = getSamples(Graph,sample_nodes,edge_list)\n",
    "\n",
    "        node_dict = {}\n",
    "        count = 0\n",
    "\n",
    "        for n in sample_nodes:\n",
    "            node_dict[n] = count\n",
    "            count+=1\n",
    "\n",
    "        yield pos_sample_edges,neg_sample_edges,sample_nodes,node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, graph=G, batch_size='', epochs=1, learning_rate=0.001):\n",
    "    optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    node_list = list(G.nodes())\n",
    "    edge_list = list(G.edges())\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        \n",
    "        batch_count = 0\n",
    "        for pos_sample, neg_sample, sample_nodes,node_dict in \\\n",
    "        createBatchesSubgraph(Graph=G, batch_size=batch_size, node_list=node_list, edge_list=edge_list):\n",
    "            \n",
    "    \n",
    "            batch_count+=1\n",
    "            node_repr = encoder(sample_nodes)\n",
    "            \n",
    "            \n",
    "            predicted_vector = torch.Tensor()\n",
    "            true_label = torch.FloatTensor([1 for i in range(len(pos_sample))]+[0 for i in range\n",
    "                                                                                   (len(neg_sample))]).view(1,-1)\n",
    "            \n",
    "            \n",
    "            i = 0\n",
    "            for a,b in pos_sample+neg_sample:\n",
    "                u = node_dict[a]\n",
    "                v = node_dict[b]\n",
    "                pred_val = F.logsigmoid(torch.sum(node_repr[u]*node_repr[v])).view(1,1)\n",
    "                \n",
    "                predicted_vector = torch.cat((predicted_vector, pred_val),dim=0)\n",
    "            \n",
    "            loss = criterion(predicted_vector,true_label)\n",
    "            \n",
    "            if batch_count%20==0:\n",
    "                print('loss: {}, batch no: {}, epoch: {}'.format(loss,batch_count,_))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRepresentations(encoder,G):\n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    node_repr = encoder(nodes)\n",
    "    \n",
    "    return node_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5, batch no: 20, epoch: 0\n",
      "loss: 0.5, batch no: 40, epoch: 0\n",
      "loss: 0.5, batch no: 60, epoch: 0\n",
      "loss: 0.5, batch no: 80, epoch: 0\n",
      "loss: 0.5, batch no: 100, epoch: 0\n"
     ]
    }
   ],
   "source": [
    "input_size = feature.shape[1]\n",
    "hidden_size = 100\n",
    "encoder = Encoder(feature,G,input_size,hidden_size)\n",
    "batch_size = 50\n",
    "train(encoder,graph=G,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_nodes = random.sample(list(G.nodes()),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot(encoder(sample_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[351]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(nx.neighbors(G,351)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[346, 1194]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nx.neighbors(G,351))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr2 = list(nx.neighbors(G,346)) + list(nx.neighbors(G,1194))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nbr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(nbr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
