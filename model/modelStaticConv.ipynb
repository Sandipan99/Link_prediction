{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from torch.nn.utils import rnn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 1033\n"
     ]
    }
   ],
   "source": [
    "with open('../Dataset/Cora/cora.cites') as fs:\n",
    "    for line in fs:\n",
    "        temp = list(map(int,line.strip().split()))\n",
    "        print(temp[0],temp[1])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct network\n",
    "G = nx.Graph()\n",
    "count = 0\n",
    "node_list = {} # assign a id of 0 - n (n nodes...)\n",
    "with open('../Dataset/Cora/cora.cites') as fs:\n",
    "    for line in fs:\n",
    "        u,v = map(int,line.strip().split())\n",
    "        if u not in node_list:\n",
    "            node_list[u] = count\n",
    "            count+=1\n",
    "        if v not in node_list:\n",
    "            node_list[v] = count\n",
    "            count+=1\n",
    "        G.add_edge(node_list[u],node_list[v])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining node features...\n",
    "feature = [[] for i in range(len(node_list))]\n",
    "label = {}\n",
    "with open('../Dataset/Cora/cora.content') as fs:\n",
    "    for line in fs:\n",
    "        temp = line.strip().split()\n",
    "        node = node_list[int(temp[0])]\n",
    "        label = temp[-1]\n",
    "        feature[node] = list(map(int,temp[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = torch.FloatTensor(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,feature,graph,input_size,hidden_size,output_size):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.feature = feature\n",
    "        self.graph = graph\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.W_1 = nn.Parameter(torch.rand(input_size,hidden_size))\n",
    "        self.W_2 = nn.Parameter(torch.rand(input_size,hidden_size))\n",
    "        \n",
    "        self.U_1 = nn.Parameter(torch.rand(hidden_size))\n",
    "        self.U_2 = nn.Parameter(torch.rand(hidden_size))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "        \n",
    "    def forward(self,node_sample):\n",
    "        \n",
    "        C_n_1_u = torch.matmul(feature,self.W_1)\n",
    "        \n",
    "        C_n_2_u = torch.matmul(feature,self.W_2)\n",
    "        \n",
    "        s_node_repr = torch.Tensor()\n",
    "        \n",
    "        for node in node_sample:\n",
    "            \n",
    "            nbr_1 = torch.Tensor()\n",
    "            nbr_2 = torch.Tensor()\n",
    "            # obtaining the first hop neighbors\n",
    "            neighbors_1 = list(nx.neighbors(G,node))\n",
    "            \n",
    "            # obtaining the second hop neighbors\n",
    "            neighbors_2 = []\n",
    "            for n in neighbors_1:\n",
    "                nbr_1 = torch.cat((nbr_1,feature[n]),dim=0) # getting the vectors of neighbors\n",
    "                neighbors_2 += list(nx.neighbors(G,n))\n",
    "            \n",
    "            neighbors_2 = list(set(neighbors_2))\n",
    "            \n",
    "            for n in neighbors_2:\n",
    "                nbr_2 = torch.cat((nbr_2,feature[n]),dim=0) # getting vectors of two-hop neighbors\n",
    "            \n",
    "            # calculate attention weights for 1-hop neighbors\n",
    "            \n",
    "            att_wt_1 = self.softmax(torch.sum(nbr_1*self.U_1).view(-1,1))\n",
    "            att_wt_2 = self.softmax(torch.sum(nbr_2*self.U_2).view(-1,1))\n",
    "            \n",
    "            output = torch.cat((torch.sum(nbr_1,att_wt_1,dim=0),torch.sum(nbr_2,att_wt_2,dim=0)),dim=1)\n",
    "            \n",
    "            s_node_repr = torch.cat((s_node_repr,output),dim=0)\n",
    "            \n",
    "        return s_node_repr    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(node_sample,s_node_sepr):\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomWalk(G,node,walk_length = 3,walk_num=10): # finding list of similar nodes\n",
    "    sim_nodes = Counter()\n",
    "    for i in range(walk_num):\n",
    "        l = 0\n",
    "        c_node = node\n",
    "        while(l<walk_length):\n",
    "            n = random.select(list(nx.neighbors(G,c_node)),1)\n",
    "            sim_nodes[n]+=1\n",
    "            c_node = n\n",
    "            l+=1\n",
    "    return list(sim_nodes)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSimilarNodes(G):\n",
    "    similar_nodes = {}\n",
    "    for node in G.nodes():\n",
    "        similar_nodes[node] = randomWalk(G,node)\n",
    "    return similar_nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSamples(G,sample_nodes,neg_sample_size): # generates positive and negative samples for a given batch of nodes\n",
    "    pos_sample_edges = list(filter(lambda x:x[0] in sample_nodes and x[1] in sample_nodes,all_edges))\n",
    "    neg_sample_edges = []\n",
    "    \n",
    "    i=0\n",
    "    while i<neg_sample_size:\n",
    "        u,v = random.sample(sample_nodes,2)\n",
    "        if (u,v) not in pos_sample_edges and (v,u) not in pos_sample_edges:\n",
    "            neg_sample_edges.append((u,v))\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def createBatches(Graph = G,batch_size = l):\n",
    "batch_size = 100\n",
    "node_list = list(G.nodes())\n",
    "random.shuffle(node_list)\n",
    "all_edges = list(G.edges())\n",
    "neg_sample_size = \n",
    "num_batches = int(len(node_list)/batch_size)+1\n",
    "for i in range(num_batches):\n",
    "    # get nodes for batches...\n",
    "    if i<num_batches-1:\n",
    "        sample_nodes = node_list[i*batch_size:(i+1)*batch_size]\n",
    "    else:\n",
    "        sample_nodes = node_list[i*batch_size:]\n",
    "\n",
    "    # find positive and negative samples for a batch\n",
    "    pos_sample_edges, neg_sample_edges = getSamples(G,sample_nodes,neg_sample_size)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (0, 3), (0, 4)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = [0,2,3,4]\n",
    "list(filter(lambda x:x[0] in samp and x[1] in samp,list(G.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [(2,3),(7,8)]\n",
    "list(filter(lambda x:(x[0] in samp and x[1] in samp),edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3,4]).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([5,6,7,8]).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.cat((x,y),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  9, 16],\n",
       "        [ 5, 12, 21, 32]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = torch.sum(z*x,dim=1).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([380, 480, 580, 680])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(z*wt,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30,  60,  90, 120],\n",
       "        [350, 420, 490, 560]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z*wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Counter()\n",
    "for i in range(9):\n",
    "    x[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,v = random.sample(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
